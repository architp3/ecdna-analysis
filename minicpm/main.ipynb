{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d769f50a-daa5-45a8-8d90-dc577349cf46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a59a2e2-c65a-4830-a05c-93aa3bdccc38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import csv\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab93fb4-cb8d-4c07-ad59-3760d02820f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b38a4698-1025-44cd-b5ff-bb6cbbdd6f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc4680558d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f29b11c-ed34-4e91-8813-40e4c6375c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c2ad43-6250-44a6-96e8-75bfc99be187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f0e0f888204a3aa024b843763214fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('openbmb/MiniCPM-V-2', trust_remote_code=True, torch_dtype=torch.bfloat16)\n",
    "model = model.to(device='cuda', dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-2', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc00ac1-915e-44b7-bbaa-9dc7c8a15c31",
   "metadata": {},
   "source": [
    "#### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f0f8180-dc92-4fe6-b8a7-1b9ef530538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(context, question, image_str, output, actual, filename='output.csv'):\n",
    "    # Check if the file already exists\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    \n",
    "    # Open the file in append mode, create if it doesn't exist\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # If the file does not exist, write the headers\n",
    "        if not file_exists:\n",
    "            writer.writerow(['Context', 'Question', 'Image_Path', 'Output', 'Actual'])\n",
    "            file_exists = True\n",
    "        # Write the data row\n",
    "        writer.writerow([context, question, image_str, output, actual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13aab4af-8dea-4f3e-af88-5f29291983cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truths(file_path):\n",
    "    gt_path = os.path.join(file_path, 'test_im_ec_quantification.csv')\n",
    "    df = pd.read_csv(gt_path)\n",
    "    return dict(zip(df['image name'], df['# of ec']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f484fc6-3ebc-4d05-8954-b8a129c3dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_img(file_path, ground_truths, img_path, img_context, question, temperature, filename):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-2', trust_remote_code=True)\n",
    "    model.eval()\n",
    "    full_image = os.path.join(file_path, img_path)\n",
    "    img = Image.open(full_image).convert('RGB')\n",
    "\n",
    "    img_tif = img_path.split(\".\")[0] + \".tif\"\n",
    "    ground_truth = ground_truths.get(img_tif, 'Unknown')\n",
    "    \n",
    "    msgs = [{'role': 'user', 'content': question}]\n",
    "\n",
    "    \n",
    "    res, context, _ = model.chat(\n",
    "        image=img,\n",
    "        msgs=msgs,\n",
    "        context=img_context,\n",
    "        tokenizer=tokenizer,\n",
    "        sampling=True,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    save_to_csv(img_context, question, img_path, res, ground_truth, filename + \".csv\")\n",
    "        \n",
    "    return res, img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3088b4a4-f3a9-4f92-ac0c-f7b2f4b34049",
   "metadata": {},
   "source": [
    "#### workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c185b92-7d22-4e51-bac4-687eaf526e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  39%|███▉      | 465/1189 [07:43<13:37,  1.13s/it]"
     ]
    }
   ],
   "source": [
    "file_path = \"../test_im_data\"\n",
    "file_path_l = os.path.join(file_path, \"labels\")\n",
    "temperature = 0.7\n",
    "context = 'You are a pathologist examing cell imagery.'\n",
    "question = 'Identify the count of ecDNA. Return a numerical answer only'\n",
    "filename = 'test'\n",
    "\n",
    "ground_truth = load_ground_truths(file_path)\n",
    "\n",
    "files = [f for f in os.listdir(file_path_l) if f.endswith('.png')]\n",
    "\n",
    "\n",
    "results = []\n",
    "for img_str in tqdm(files, desc=\"Processing Images\"):\n",
    "    res, img = eval_img(file_path_l, ground_truth, img_str, context, question, temperature, filename)\n",
    "    results.append((img_str, res, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2760b84b-46bb-4fa6-98c3-aa8c86e35e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(100)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-2', trust_remote_code=True)\n",
    "\n",
    "# image = Image.open('../sampled/11.png').convert('RGB')\n",
    "\n",
    "# # First round chat \n",
    "# question = \"What is the landform in the picture?\"\n",
    "# msgs = [{'role': 'user', 'content': [image, question]}]\n",
    "\n",
    "# answer = model.chat(\n",
    "#     msgs=msgs,\n",
    "#     tokenizer=tokenizer\n",
    "# )\n",
    "# print(answer)\n",
    "\n",
    "# # Second round chat, pass history context of multi-turn conversation\n",
    "# msgs.append({\"role\": \"assistant\", \"content\": [answer]})\n",
    "# msgs.append({\"role\": \"user\", \"content\": [\"What should I pay attention to when traveling here?\"]})\n",
    "\n",
    "# answer = model.chat(\n",
    "#     msgs=msgs,\n",
    "#     tokenizer=tokenizer\n",
    "# )\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47fb723-7006-41b4-8946-52f102eef296",
   "metadata": {},
   "source": [
    "### todo\n",
    "* n-shot learning with 0, 1, and say 10\n",
    "* graph results of different learning types\n",
    "* understand minicpm llm aspect\n",
    "* different context analysis\n",
    "* descriptions of ecdna"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
